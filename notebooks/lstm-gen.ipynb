{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "import os.path\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from artstat import util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'artstat.util' from '../src/artstat/util.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/pmilovanov/hg/my/data/gallery-pr/all\"\n",
    "\n",
    "path_train = os.path.join(datadir, \"train\")\n",
    "path_test = os.path.join(datadir, \"test\")\n",
    "\n",
    "glove = \"/home/pmilovanov/data/glove/glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vocab = util.load_vocab(\"../vocab.txt\", 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = util.load_embeddings(vocab, 300, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix.shape\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 54/22860 [00:00<00:42, 539.23it/s]\n"
     ]
    }
   ],
   "source": [
    "imp.reload(util)\n",
    "\n",
    "seqlen = 128\n",
    "stride = 96\n",
    "X, Y, Xu, Yu = util.load_data_sequences(path_train, vocab, seqlen, stride, numfiles=100)\n",
    "Yfake = np.ones((Yu.shape[0], 128), dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = K.Input((seqlen,), dtype=\"int32\", name=\"input_x\")\n",
    "input_xu = K.Input((seqlen,), dtype=\"float32\", name=\"input_xu\")\n",
    "input_y = K.Input((seqlen,), dtype=\"int32\", name=\"input_y\")\n",
    "input_yu = K.Input((seqlen,), dtype=\"float32\", name=\"input_yu\")\n",
    "\n",
    "reshaper_u  = K.layers.Reshape((seqlen,1))\n",
    "resh_xu = reshaper_u(input_xu)\n",
    "resh_yu = reshaper_u(input_yu)\n",
    "\n",
    "dim = emb_matrix.shape[1] + 1\n",
    "\n",
    "L_emb = K.layers.Embedding(emb_matrix.shape[0], \n",
    "                           emb_matrix.shape[1], \n",
    "                           input_length=seqlen, \n",
    "                          trainable=False,\n",
    "                           weights=[emb_matrix],\n",
    "                           name=\"embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemb = L_emb\n",
    "emb_x = Lemb(input_x)\n",
    "emb_y = Lemb(input_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lconcat = K.layers.Concatenate()\n",
    "concat_x = Lconcat([emb_x, resh_xu])\n",
    "concat_y = Lconcat([emb_y, resh_yu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(301)])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm =  K.layers.CuDNNLSTM(256, return_sequences=True)(concat_x)\n",
    "lstm =  K.layers.CuDNNLSTM(256, return_sequences=True)(concat_x)\n",
    "#lstm = K.layers.CuDNNLSTM(256, return_sequences=True)(lstm)\n",
    "dense = K.layers.BatchNormalization()(lstm)\n",
    "dense = K.layers.Dense(1024, activation=\"relu\")(dense)\n",
    "dense = K.layers.BatchNormalization()(dense)\n",
    "dense = K.layers.Dense(1024, activation=\"relu\")(dense)\n",
    "dense = K.layers.BatchNormalization()(dense)\n",
    "dense = K.layers.Dense(dim, activation=\"sigmoid\")(dense)\n",
    "\n",
    "dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128), Dimension(301)])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"truediv_10:0\", shape=(6, 10), dtype=float32)\n",
      "[[ 0.21235225 -0.24089421  0.31849968 -0.06436007  0.17942332  0.07761139\n",
      "  -0.03735921 -0.4905576  -0.03229325  0.26053354]\n",
      " [ 0.20631321  0.23059595  0.544917    0.05250033 -0.25267574  0.20119864\n",
      "  -0.46314734 -0.22291759 -0.2247903   0.10972435]\n",
      " [-0.19505201 -0.14896832 -0.23880954 -0.11091805 -0.27862975  0.18430588\n",
      "   0.07154792  0.11619413  0.00159042 -0.05508105]\n",
      " [ 0.05807852  0.01318557 -0.03135784 -0.07669993  0.12554404  0.3934909\n",
      "   0.37591565  0.22530068  0.69247246 -0.05288764]\n",
      " [-0.2564594  -0.17248338  0.1345384   0.0564288   0.04351333 -0.13689366\n",
      "  -0.00105489 -0.13824148  0.07972438 -0.0160603 ]\n",
      " [ 0.02176644  0.25392687  0.14088386 -0.02723447  0.12549354 -0.09937479\n",
      "   0.62498444 -0.31078127  0.47853023 -0.45502126]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128)])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#proximity = K.layers.dot([resh_x, resh_y], axes=-1, normalize=True)\n",
    "import keras as K\n",
    "from keras import backend as B\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "epsi = 0.0001\n",
    "\n",
    "def realdot(a,b):\n",
    "    d = K.layers.multiply([a, b])\n",
    "    return B.sum(d, axis=-1)\n",
    "\n",
    "def dotlayer(x):\n",
    "    a,b = x\n",
    "    \n",
    "    p = realdot(a,b)\n",
    "    \n",
    "    an = B.sqrt(realdot(a,a) + B.epsilon())\n",
    "    bn = B.sqrt(realdot(b,b) + B.epsilon())\n",
    "    \n",
    "    return tf.divide(p, K.layers.multiply([an, bn]) + B.epsilon())\n",
    "    \n",
    "def test2(x):\n",
    "    a,b = x\n",
    "    \n",
    "    q = K.layers.subtract([a,b])\n",
    "    q = B.sum(q, axis=-1)\n",
    "#    q = B.mean(q, axis=-1, keepdims=True)\n",
    "    return q\n",
    "\n",
    "qA = B.variable(np.random.randn(6,10,12)) #np.array([[1,0], [3,4]]))\n",
    "qB = B.variable(np.random.randn(6,10,12)) #np.array([[0,0], [-7,-8]]))\n",
    "qq = dotlayer([qA, qB])\n",
    "print(qq)\n",
    "print(B.eval(qq))    \n",
    "    \n",
    "proximity = K.layers.Lambda(dotlayer)([concat_y, dense])\n",
    "    \n",
    "#proximity = K.layers.dot([concat_y, dense], axes=(2,2),normalize=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#proximity = K.layers.average(proximity, axis=-1)\n",
    "proximity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = K.Model(inputs=[input_x, input_xu, input_y, input_yu],\n",
    "               outputs=[proximity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 500\n",
    "z = model.predict([X[:i], Xu[:i], Y[:i], Yu[:i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = K.losses.mean_squared_error(Yfake[:i], z)\n",
    "\n",
    "L = K.backend.eval(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_y (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_yu (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_x (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_xu (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 128, 300)     30000300    input_x[0][0]                    \n",
      "                                                                 input_y[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 128, 1)       0           input_xu[0][0]                   \n",
      "                                                                 input_yu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 301)     0           embedding[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 reshape_3[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_9 (CuDNNLSTM)        (None, 128, 256)     572416      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 256)     1024        cu_dnnlstm_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 128, 1024)    263168      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 128, 1024)    4096        dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128, 1024)    1049600     batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 128, 1024)    4096        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128, 301)     308525      batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 128)          0           concatenate_3[1][0]              \n",
      "                                                                 dense_28[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 32,203,225\n",
      "Trainable params: 2,198,317\n",
      "Non-trainable params: 30,004,908\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = B.gradients(L, L_dense.get_weights())\n",
    "\n",
    "g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = K.optimizers.Adam(lr=0.01)\n",
    "model.compile(opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000000\n",
      "617/617 [==============================] - 2s 3ms/step - loss: 0.9712\n",
      "Epoch 2/1000000\n",
      "617/617 [==============================] - 0s 501us/step - loss: 0.8673\n",
      "Epoch 3/1000000\n",
      "617/617 [==============================] - 0s 509us/step - loss: 0.8007\n",
      "Epoch 4/1000000\n",
      "617/617 [==============================] - 0s 501us/step - loss: 0.7639\n",
      "Epoch 5/1000000\n",
      "617/617 [==============================] - 0s 480us/step - loss: 0.7206\n",
      "Epoch 6/1000000\n",
      "617/617 [==============================] - 0s 551us/step - loss: 0.6765\n",
      "Epoch 7/1000000\n",
      "617/617 [==============================] - 0s 555us/step - loss: 0.6311\n",
      "Epoch 8/1000000\n",
      "617/617 [==============================] - 0s 532us/step - loss: 0.5783\n",
      "Epoch 9/1000000\n",
      "617/617 [==============================] - 0s 495us/step - loss: 0.5386\n",
      "Epoch 10/1000000\n",
      "617/617 [==============================] - 0s 516us/step - loss: 0.5060\n",
      "Epoch 11/1000000\n",
      "617/617 [==============================] - 0s 595us/step - loss: 0.4843\n",
      "Epoch 12/1000000\n",
      "617/617 [==============================] - 0s 512us/step - loss: 0.4752\n",
      "Epoch 13/1000000\n",
      "617/617 [==============================] - 0s 518us/step - loss: 0.4660\n",
      "Epoch 14/1000000\n",
      "617/617 [==============================] - 0s 514us/step - loss: 0.4579\n",
      "Epoch 15/1000000\n",
      "617/617 [==============================] - 0s 522us/step - loss: 0.4483\n",
      "Epoch 16/1000000\n",
      "617/617 [==============================] - 0s 471us/step - loss: 0.4441\n",
      "Epoch 17/1000000\n",
      "617/617 [==============================] - 0s 630us/step - loss: 0.4371\n",
      "Epoch 18/1000000\n",
      "617/617 [==============================] - 0s 509us/step - loss: 0.4367\n",
      "Epoch 19/1000000\n",
      "617/617 [==============================] - 0s 522us/step - loss: 0.4329\n",
      "Epoch 20/1000000\n",
      "617/617 [==============================] - 0s 521us/step - loss: 0.4305\n",
      "Epoch 21/1000000\n",
      "617/617 [==============================] - 0s 525us/step - loss: 0.4278\n",
      "Epoch 22/1000000\n",
      "617/617 [==============================] - 0s 503us/step - loss: 0.4258\n",
      "Epoch 23/1000000\n",
      "617/617 [==============================] - 0s 599us/step - loss: 0.4236\n",
      "Epoch 24/1000000\n",
      "617/617 [==============================] - 0s 555us/step - loss: 0.4218\n",
      "Epoch 25/1000000\n",
      "617/617 [==============================] - 0s 523us/step - loss: 0.4203\n",
      "Epoch 26/1000000\n",
      "617/617 [==============================] - 0s 534us/step - loss: 0.4188\n",
      "Epoch 27/1000000\n",
      "617/617 [==============================] - 0s 547us/step - loss: 0.4180\n",
      "Epoch 28/1000000\n",
      "617/617 [==============================] - 0s 528us/step - loss: 0.4191\n",
      "Epoch 29/1000000\n",
      "617/617 [==============================] - 0s 533us/step - loss: 0.4185\n",
      "Epoch 30/1000000\n",
      "617/617 [==============================] - 0s 548us/step - loss: 0.4163\n",
      "Epoch 31/1000000\n",
      "617/617 [==============================] - 0s 536us/step - loss: 0.4148\n",
      "Epoch 32/1000000\n",
      "617/617 [==============================] - 0s 538us/step - loss: 0.4139\n",
      "Epoch 33/1000000\n",
      "617/617 [==============================] - 0s 627us/step - loss: 0.4150\n",
      "Epoch 34/1000000\n",
      "617/617 [==============================] - 0s 535us/step - loss: 0.4184\n",
      "Epoch 35/1000000\n",
      "617/617 [==============================] - 0s 528us/step - loss: 0.4182\n",
      "Epoch 36/1000000\n",
      "617/617 [==============================] - 0s 552us/step - loss: 0.4144\n",
      "Epoch 37/1000000\n",
      "617/617 [==============================] - 0s 540us/step - loss: 0.4146\n",
      "Epoch 38/1000000\n",
      "617/617 [==============================] - 0s 546us/step - loss: 0.4112\n",
      "Epoch 39/1000000\n",
      "617/617 [==============================] - 0s 560us/step - loss: 0.4100\n",
      "Epoch 40/1000000\n",
      "617/617 [==============================] - 0s 520us/step - loss: 0.4101\n",
      "Epoch 41/1000000\n",
      "617/617 [==============================] - 0s 549us/step - loss: 0.4086\n",
      "Epoch 42/1000000\n",
      "617/617 [==============================] - 0s 603us/step - loss: 0.4072\n",
      "Epoch 43/1000000\n",
      "617/617 [==============================] - 0s 580us/step - loss: 0.4062\n",
      "Epoch 44/1000000\n",
      "617/617 [==============================] - 0s 521us/step - loss: 0.4050\n",
      "Epoch 45/1000000\n",
      "617/617 [==============================] - 0s 522us/step - loss: 0.4041\n",
      "Epoch 46/1000000\n",
      "617/617 [==============================] - 0s 539us/step - loss: 0.4030\n",
      "Epoch 47/1000000\n",
      "617/617 [==============================] - 0s 541us/step - loss: 0.4024\n",
      "Epoch 48/1000000\n",
      "617/617 [==============================] - 0s 580us/step - loss: 0.4011\n",
      "Epoch 49/1000000\n",
      "617/617 [==============================] - 0s 532us/step - loss: 0.4002\n",
      "Epoch 50/1000000\n",
      "617/617 [==============================] - 0s 549us/step - loss: 0.3993\n",
      "Epoch 51/1000000\n",
      "617/617 [==============================] - 0s 555us/step - loss: 0.3987\n",
      "Epoch 52/1000000\n",
      "617/617 [==============================] - 0s 554us/step - loss: 0.3975\n",
      "Epoch 53/1000000\n",
      "617/617 [==============================] - 0s 600us/step - loss: 0.3970\n",
      "Epoch 54/1000000\n",
      "617/617 [==============================] - 0s 496us/step - loss: 0.3964\n",
      "Epoch 55/1000000\n",
      "617/617 [==============================] - 0s 551us/step - loss: 0.3954\n",
      "Epoch 56/1000000\n",
      "617/617 [==============================] - 0s 519us/step - loss: 0.3946\n",
      "Epoch 57/1000000\n",
      "617/617 [==============================] - 0s 617us/step - loss: 0.3938\n",
      "Epoch 58/1000000\n",
      "617/617 [==============================] - 0s 476us/step - loss: 0.3930\n",
      "Epoch 59/1000000\n",
      "617/617 [==============================] - 0s 477us/step - loss: 0.3923\n",
      "Epoch 60/1000000\n",
      "617/617 [==============================] - 0s 542us/step - loss: 0.3915\n",
      "Epoch 61/1000000\n",
      "617/617 [==============================] - 0s 567us/step - loss: 0.3908\n",
      "Epoch 62/1000000\n",
      "617/617 [==============================] - 0s 477us/step - loss: 0.3902\n",
      "Epoch 63/1000000\n",
      "617/617 [==============================] - 0s 508us/step - loss: 0.3895\n",
      "Epoch 64/1000000\n",
      "617/617 [==============================] - 0s 553us/step - loss: 0.3888\n",
      "Epoch 65/1000000\n",
      "617/617 [==============================] - 0s 609us/step - loss: 0.3882\n",
      "Epoch 66/1000000\n",
      "617/617 [==============================] - 0s 612us/step - loss: 0.3873\n",
      "Epoch 67/1000000\n",
      "617/617 [==============================] - 0s 494us/step - loss: 0.3863\n",
      "Epoch 68/1000000\n",
      "617/617 [==============================] - 0s 555us/step - loss: 0.3855\n",
      "Epoch 69/1000000\n",
      "617/617 [==============================] - 0s 536us/step - loss: 0.3847\n",
      "Epoch 70/1000000\n",
      "617/617 [==============================] - 0s 538us/step - loss: 0.3840\n",
      "Epoch 71/1000000\n",
      "617/617 [==============================] - 0s 538us/step - loss: 0.3840\n",
      "Epoch 72/1000000\n",
      "617/617 [==============================] - 0s 577us/step - loss: 0.3835\n",
      "Epoch 73/1000000\n",
      "617/617 [==============================] - 0s 542us/step - loss: 0.3845\n",
      "Epoch 74/1000000\n",
      "617/617 [==============================] - 0s 577us/step - loss: 0.3830\n",
      "Epoch 75/1000000\n",
      "617/617 [==============================] - 0s 557us/step - loss: 0.3827\n",
      "Epoch 76/1000000\n",
      "617/617 [==============================] - 0s 642us/step - loss: 0.3820\n",
      "Epoch 77/1000000\n",
      "617/617 [==============================] - 0s 508us/step - loss: 0.3805\n",
      "Epoch 78/1000000\n",
      "617/617 [==============================] - 0s 533us/step - loss: 0.3800\n",
      "Epoch 79/1000000\n",
      "617/617 [==============================] - 0s 521us/step - loss: 0.3792\n",
      "Epoch 80/1000000\n",
      "617/617 [==============================] - 0s 511us/step - loss: 0.3786\n",
      "Epoch 81/1000000\n",
      "617/617 [==============================] - 0s 557us/step - loss: 0.3773\n",
      "Epoch 82/1000000\n",
      "617/617 [==============================] - 0s 549us/step - loss: 0.3764\n",
      "Epoch 83/1000000\n",
      "617/617 [==============================] - 0s 534us/step - loss: 0.3762\n",
      "Epoch 84/1000000\n",
      "617/617 [==============================] - 0s 565us/step - loss: 0.3745\n",
      "Epoch 85/1000000\n",
      "617/617 [==============================] - 0s 568us/step - loss: 0.3742\n",
      "Epoch 86/1000000\n",
      "617/617 [==============================] - 0s 536us/step - loss: 0.3732\n",
      "Epoch 87/1000000\n",
      "617/617 [==============================] - 0s 570us/step - loss: 0.3722\n",
      "Epoch 88/1000000\n",
      "617/617 [==============================] - 0s 556us/step - loss: 0.3717\n",
      "Epoch 89/1000000\n",
      "617/617 [==============================] - 0s 589us/step - loss: 0.3706\n",
      "Epoch 90/1000000\n",
      "617/617 [==============================] - 0s 524us/step - loss: 0.3698\n",
      "Epoch 91/1000000\n",
      "617/617 [==============================] - 0s 597us/step - loss: 0.3688\n",
      "Epoch 92/1000000\n",
      "617/617 [==============================] - 0s 516us/step - loss: 0.3681\n",
      "Epoch 93/1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617/617 [==============================] - 0s 515us/step - loss: 0.3689\n",
      "Epoch 94/1000000\n",
      "617/617 [==============================] - 0s 595us/step - loss: 0.3698\n",
      "Epoch 95/1000000\n",
      "617/617 [==============================] - 0s 490us/step - loss: 0.3731\n",
      "Epoch 96/1000000\n",
      "617/617 [==============================] - 0s 512us/step - loss: 0.3699\n",
      "Epoch 97/1000000\n",
      "617/617 [==============================] - 0s 542us/step - loss: 0.3690\n",
      "Epoch 98/1000000\n",
      "617/617 [==============================] - 0s 529us/step - loss: 0.3672\n",
      "Epoch 99/1000000\n",
      "617/617 [==============================] - 0s 521us/step - loss: 0.3660\n",
      "Epoch 100/1000000\n",
      "617/617 [==============================] - 0s 505us/step - loss: 0.3653\n",
      "Epoch 101/1000000\n",
      "617/617 [==============================] - 0s 504us/step - loss: 0.3641\n",
      "Epoch 102/1000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-ad19461fffc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mYfake\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1375\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m         return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1377\u001b[0;31m             self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([X, Xu, Y, Yu], [Yfake], batch_size=1024, epochs=1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = K.Model([input_x, input_xu], [dense])\n",
    "predictor.compile(opt, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "norm_emb_matrix =  pp.normalize(Lemb.get_weights()[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as\n",
      "the\n",
      "be\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "begin\n",
      "the\n",
      "architectural\n",
      "example\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n",
      "the\n",
      "as\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "gen = X[i].tolist()\n",
    "genu = Xu[i].tolist()\n",
    "\n",
    "tX = np.zeros((1, seqlen), dtype=\"int32\")\n",
    "tXu = np.zeros((1, seqlen), dtype=\"float32\")\n",
    "results = []\n",
    "\n",
    "iterations = 128\n",
    "for j in range(iterations):\n",
    "    tX[0,:] = np.array(gen[-seqlen:], \"int32\")\n",
    "    tXu[0,:] = np.array(genu[-seqlen:], \"float32\")\n",
    "    #print(tX)\n",
    "    xv, xuv = 0, 0.0\n",
    "    z = predictor.predict([tX, tXu])\n",
    "    if False: #z[0, -1, -1] > 0.9:\n",
    "        xuv = 1.0\n",
    "        results.append(\"<UNK>\")\n",
    "    else:\n",
    "        we = np.transpose(pp.normalize(np.reshape(z[0, -1, :300], (1,300))))\n",
    "#        print(np.linalg.norm(we))\n",
    "#        scores = np.matmul(norm_emb_matrix, we)\n",
    "#        print(scores)\n",
    "#        print(np.min(scores))\n",
    "#        break\n",
    "        xv = np.argmax(np.matmul(norm_emb_matrix, we))\n",
    "        if xv:\n",
    "            results.append(words[xv])\n",
    "        else:\n",
    "            results.append(\"<EMPTY>\")\n",
    "    gen.append(xv)\n",
    "    genu.append(xuv)\n",
    "    print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3547268e-16 0.93638355\n"
     ]
    }
   ],
   "source": [
    "print(np.min(z), np.max(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_emb_matrix =  preprocessing.normalize(emb_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "zn = preprocessing.normalize(z[0,:], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "we = zn[-1, :300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.matmul(norm_emb_matrix, we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "idx = np.argmax(scores)\n",
    "print(idx)\n",
    "word = words[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
